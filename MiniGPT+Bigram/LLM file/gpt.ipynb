{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Initialize the model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "batch_size = 64 # how many independent sequences will we process in parallel?\n",
    "block_size = 256 # what is the maximum context length for predictions?\n",
    "max_iters = 5000\n",
    "eval_interval = 50\n",
    "learning_rate = 3e-4\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "eval_iters = 200\n",
    "n_embd = 384\n",
    "n_head = 6\n",
    "n_layer = 6\n",
    "dropout = 0.2\n",
    "train_losses = []\n",
    "val_losses = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Load the data and split into training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This code snippet performs the following tasks:\n",
    "1. Sets the random seed for PyTorch.\n",
    "2. Reads the contents of the 'goods_zh_cleaned.txt' file.\n",
    "3. Creates a mapping from characters to integers.\n",
    "4. Defines encoder and decoder functions to convert between strings and lists of integers.\n",
    "5. Splits the data into training and validation sets.\n",
    "\"\"\"\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "# wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
    "with open('ng-video-lecture-master/goods_zh_cleaned.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "# here are all the unique characters that occur in this text\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "\n",
    "# create a mapping from characters to integers\n",
    "stoi = { ch:i for i,ch in enumerate(chars) }\n",
    "itos = { i:ch for i,ch in enumerate(chars) }\n",
    "encode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
    "decode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string\n",
    "\n",
    "# Train and test splits\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "n = int(0.9*len(data)) # first 90% will be train, rest val\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Define "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# data loading\n",
    "def get_batch(split):\n",
    "    \"\"\"\n",
    "    Generate a small batch of data of inputs x and targets y.\n",
    "\n",
    "    Args:\n",
    "        split (str): The split of the data ('train' or 'val').\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: The input data tensor (x).\n",
    "        torch.Tensor: The target data tensor (y).\n",
    "    \"\"\"\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    return x, y\n",
    "\n",
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    \"\"\"\n",
    "    Estimates the loss for the model on the training and validation sets.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the mean loss values for the training and validation sets.\n",
    "    \"\"\"\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out\n",
    "\n",
    "class Head(nn.Module):\n",
    "    \"\"\" one head of self-attention \"\"\"\n",
    "\n",
    "    def __init__(self, head_size):\n",
    "        \"\"\"\n",
    "        Initializes the GPT model.\n",
    "\n",
    "        Args:\n",
    "            head_size (int): The size of the attention head.\n",
    "\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass of the GPT model.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor of size (batch, time-step, channels).\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Output tensor of size (batch, time-step, head size).\n",
    "        \"\"\"\n",
    "        B, T, C = x.shape\n",
    "        k = self.key(x)   # (B, T, hs)\n",
    "        q = self.query(x) # (B, T, hs)\n",
    "        \n",
    "        # Compute attention scores (\"affinities\")\n",
    "        wei = q @ k.transpose(-2, -1) * k.shape[-1]**-0.5  # (B, T, hs) @ (B, hs, T) -> (B, T, T)\n",
    "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf'))  # (B, T, T)\n",
    "        wei = F.softmax(wei, dim=-1)  # (B, T, T)\n",
    "        wei = self.dropout(wei)\n",
    "        \n",
    "        # Perform the weighted aggregation of the values\n",
    "        v = self.value(x)  # (B, T, hs)\n",
    "        out = wei @ v  # (B, T, T) @ (B, T, hs) -> (B, T, hs)\n",
    "        \n",
    "        return out\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass of the GPT model.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor of size (batch, time-step, channels).\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Output tensor of size (batch, time-step, head size).\n",
    "        \"\"\"\n",
    "        B, T, C = x.shape\n",
    "        k = self.key(x)   # (B, T, hs)\n",
    "        q = self.query(x) # (B, T, hs)\n",
    "\n",
    "        # Compute attention scores (\"affinities\")\n",
    "        wei = q @ k.transpose(-2, -1) * k.shape[-1]**-0.5  # (B, T, hs) @ (B, hs, T) -> (B, T, T)\n",
    "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf'))  # (B, T, T)\n",
    "        wei = F.softmax(wei, dim=-1)  # (B, T, T)\n",
    "        wei = self.dropout(wei)\n",
    "\n",
    "        # Perform the weighted aggregation of the values\n",
    "        v = self.value(x)  # (B, T, hs)\n",
    "        out = wei @ v  # (B, T, T) @ (B, T, hs) -> (B, T, hs)\n",
    "\n",
    "        return out\n",
    "    def forward(self, x):\n",
    "        # input of size (batch, time-step, channels)\n",
    "        # output of size (batch, time-step, head size)\n",
    "        B,T,C = x.shape\n",
    "        k = self.key(x)   # (B,T,hs)\n",
    "        q = self.query(x) # (B,T,hs)\n",
    "        # compute attention scores (\"affinities\")\n",
    "        wei = q @ k.transpose(-2,-1) * k.shape[-1]**-0.5 # (B, T, hs) @ (B, hs, T) -> (B, T, T)\n",
    "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n",
    "        wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
    "        wei = self.dropout(wei)\n",
    "        # perform the weighted aggregation of the values\n",
    "        v = self.value(x) # (B,T,hs)\n",
    "        out = wei @ v # (B, T, T) @ (B, T, hs) -> (B, T, hs)\n",
    "        return out\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\" multiple heads of self-attention in parallel \"\"\"\n",
    "\n",
    "    def __init__(self, num_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
    "        self.proj = nn.Linear(head_size * num_heads, n_embd)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
    "        out = self.dropout(self.proj(out))\n",
    "        return out\n",
    "\n",
    "class FeedFoward(nn.Module):\n",
    "    \"\"\" a simple linear layer followed by a non-linearity \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embd, 4 * n_embd),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * n_embd, n_embd),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class Block(nn.Module):\n",
    "    \"\"\" Transformer block: communication followed by computation \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd, n_head):\n",
    "        # n_embd: embedding dimension, n_head: the number of heads we'd like\n",
    "        super().__init__()\n",
    "        head_size = n_embd // n_head\n",
    "        self.sa = MultiHeadAttention(n_head, head_size)\n",
    "        self.ffwd = FeedFoward(n_embd)\n",
    "        self.ln1 = nn.LayerNorm(n_embd)\n",
    "        self.ln2 = nn.LayerNorm(n_embd)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.sa(self.ln1(x))\n",
    "        x = x + self.ffwd(self.ln2(x))\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Define the GPT Language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class GPTLanguageModel(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initializes the MiniGPT model.\n",
    "\n",
    "        This method sets up the model architecture and initializes the necessary components.\n",
    "\n",
    "        Args:\n",
    "            None\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        # each token directly reads off the logits for the next token from a lookup table\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
    "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
    "        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
    "        self.ln_f = nn.LayerNorm(n_embd) # final layer norm\n",
    "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
    "\n",
    "        # better init, not covered in the original GPT video, but important, will cover in followup video\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        \"\"\"\n",
    "        Initializes the weights of the given module.\n",
    "\n",
    "        Args:\n",
    "            module (nn.Module): The module whose weights need to be initialized.\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        B, T = idx.shape\n",
    "\n",
    "        # idx and targets are both (B,T) tensor of integers\n",
    "        tok_emb = self.token_embedding_table(idx) # (B,T,C)\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)\n",
    "        x = tok_emb + pos_emb # (B,T,C)\n",
    "        x = self.blocks(x) # (B,T,C)\n",
    "        x = self.ln_f(x) # (B,T,C)\n",
    "        logits = self.lm_head(x) # (B,T,vocab_size)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx is (B, T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            # crop idx to the last block_size tokens\n",
    "            idx_cond = idx[:, -block_size:]\n",
    "            # get the predictions\n",
    "            logits, loss = self(idx_cond)\n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :] # becomes (B, C)\n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "            # append sampled index to the running sequence\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
    "        return idx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. train the GPT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.765728 M parameters\n",
      "step 0: train loss 8.3942, val loss 8.3935\n",
      "step 50: train loss 5.3730, val loss 5.3704\n",
      "step 100: train loss 4.3686, val loss 4.3773\n",
      "step 150: train loss 4.0998, val loss 4.1101\n",
      "step 200: train loss 3.9839, val loss 3.9988\n",
      "step 250: train loss 3.9023, val loss 3.9226\n",
      "step 300: train loss 3.8450, val loss 3.8672\n",
      "step 350: train loss 3.7832, val loss 3.8147\n",
      "step 400: train loss 3.7238, val loss 3.7504\n",
      "step 450: train loss 3.6442, val loss 3.6790\n",
      "step 500: train loss 3.5597, val loss 3.5883\n",
      "step 550: train loss 3.4850, val loss 3.5218\n",
      "step 600: train loss 3.4171, val loss 3.4537\n",
      "step 650: train loss 3.3545, val loss 3.3925\n",
      "step 700: train loss 3.3075, val loss 3.3466\n",
      "step 750: train loss 3.2595, val loss 3.3095\n",
      "step 800: train loss 3.2203, val loss 3.2770\n",
      "step 850: train loss 3.1789, val loss 3.2355\n",
      "step 900: train loss 3.1531, val loss 3.2134\n",
      "step 950: train loss 3.1213, val loss 3.1955\n",
      "step 1000: train loss 3.0933, val loss 3.1683\n",
      "step 1050: train loss 3.0748, val loss 3.1475\n",
      "step 1100: train loss 3.0548, val loss 3.1296\n",
      "step 1150: train loss 3.0305, val loss 3.1168\n",
      "step 1200: train loss 3.0217, val loss 3.0996\n",
      "step 1250: train loss 3.0037, val loss 3.0827\n",
      "step 1300: train loss 2.9783, val loss 3.0633\n",
      "step 1350: train loss 2.9644, val loss 3.0594\n",
      "step 1400: train loss 2.9470, val loss 3.0395\n",
      "step 1450: train loss 2.9287, val loss 3.0324\n",
      "step 1500: train loss 2.9175, val loss 3.0186\n",
      "step 1550: train loss 2.9022, val loss 3.0101\n",
      "step 1600: train loss 2.8920, val loss 3.0012\n",
      "step 1650: train loss 2.8828, val loss 2.9897\n",
      "step 1700: train loss 2.8689, val loss 2.9731\n",
      "step 1750: train loss 2.8511, val loss 2.9799\n",
      "step 1800: train loss 2.8527, val loss 2.9739\n",
      "step 1850: train loss 2.8348, val loss 2.9607\n",
      "step 1900: train loss 2.8240, val loss 2.9506\n",
      "step 1950: train loss 2.8190, val loss 2.9459\n",
      "step 2000: train loss 2.8091, val loss 2.9336\n",
      "step 2050: train loss 2.7980, val loss 2.9323\n",
      "step 2100: train loss 2.7888, val loss 2.9318\n",
      "step 2150: train loss 2.7737, val loss 2.9211\n",
      "step 2200: train loss 2.7730, val loss 2.9189\n",
      "step 2250: train loss 2.7620, val loss 2.9154\n",
      "step 2300: train loss 2.7528, val loss 2.9050\n",
      "step 2350: train loss 2.7478, val loss 2.9090\n",
      "step 2400: train loss 2.7340, val loss 2.8942\n",
      "step 2450: train loss 2.7239, val loss 2.8891\n",
      "step 2500: train loss 2.7176, val loss 2.8797\n",
      "step 2550: train loss 2.7092, val loss 2.8818\n",
      "step 2600: train loss 2.7064, val loss 2.8804\n",
      "step 2650: train loss 2.7056, val loss 2.8706\n",
      "step 2700: train loss 2.6931, val loss 2.8682\n",
      "step 2750: train loss 2.6873, val loss 2.8659\n",
      "step 2800: train loss 2.6748, val loss 2.8539\n",
      "step 2850: train loss 2.6678, val loss 2.8545\n",
      "step 2900: train loss 2.6640, val loss 2.8561\n",
      "step 2950: train loss 2.6505, val loss 2.8489\n",
      "step 3000: train loss 2.6504, val loss 2.8500\n",
      "step 3050: train loss 2.6449, val loss 2.8491\n",
      "step 3100: train loss 2.6383, val loss 2.8419\n",
      "step 3150: train loss 2.6351, val loss 2.8455\n",
      "step 3200: train loss 2.6281, val loss 2.8425\n",
      "step 3250: train loss 2.6186, val loss 2.8349\n",
      "step 3300: train loss 2.6191, val loss 2.8362\n",
      "step 3350: train loss 2.6087, val loss 2.8364\n",
      "step 3400: train loss 2.6048, val loss 2.8282\n",
      "step 3450: train loss 2.6005, val loss 2.8261\n",
      "step 3500: train loss 2.5953, val loss 2.8316\n",
      "step 3550: train loss 2.5894, val loss 2.8300\n",
      "step 3600: train loss 2.5885, val loss 2.8231\n",
      "step 3650: train loss 2.5745, val loss 2.8200\n",
      "step 3700: train loss 2.5692, val loss 2.8123\n",
      "step 3750: train loss 2.5712, val loss 2.8181\n",
      "step 3800: train loss 2.5656, val loss 2.8221\n",
      "step 3850: train loss 2.5607, val loss 2.8131\n",
      "step 3900: train loss 2.5540, val loss 2.8051\n",
      "step 3950: train loss 2.5515, val loss 2.8067\n",
      "step 4000: train loss 2.5450, val loss 2.8012\n",
      "step 4050: train loss 2.5406, val loss 2.8095\n",
      "step 4100: train loss 2.5359, val loss 2.7903\n",
      "step 4150: train loss 2.5265, val loss 2.8017\n",
      "step 4200: train loss 2.5280, val loss 2.7990\n",
      "step 4250: train loss 2.5154, val loss 2.7985\n",
      "step 4300: train loss 2.5218, val loss 2.7999\n",
      "step 4350: train loss 2.5163, val loss 2.7967\n",
      "step 4400: train loss 2.5080, val loss 2.7947\n",
      "step 4450: train loss 2.5058, val loss 2.7869\n",
      "step 4500: train loss 2.5014, val loss 2.7960\n",
      "step 4550: train loss 2.4912, val loss 2.7854\n",
      "step 4600: train loss 2.4899, val loss 2.7808\n",
      "step 4650: train loss 2.4844, val loss 2.7813\n",
      "step 4700: train loss 2.4764, val loss 2.7795\n",
      "step 4750: train loss 2.4797, val loss 2.7910\n",
      "step 4800: train loss 2.4733, val loss 2.7801\n",
      "step 4850: train loss 2.4713, val loss 2.7759\n",
      "step 4900: train loss 2.4646, val loss 2.7781\n",
      "step 4950: train loss 2.4619, val loss 2.7790\n",
      "step 4999: train loss 2.4647, val loss 2.7740\n",
      "Training took 5059.88 seconds\n"
     ]
    }
   ],
   "source": [
    "def train_model(max_iters, eval_interval, learning_rate):\n",
    "    \"\"\"\n",
    "    Train the GPT language model.\n",
    "\n",
    "    Args:\n",
    "        max_iters (int): The maximum number of iterations for training.\n",
    "        eval_interval (int): The interval at which to evaluate the loss on train and val sets.\n",
    "        learning_rate (float): The learning rate for the optimizer.\n",
    "\n",
    "    Returns:\n",
    "        train_losses (list): List of train losses at each evaluation interval.\n",
    "        val_losses (list): List of validation losses at each evaluation interval.\n",
    "    \"\"\"\n",
    "    model = GPTLanguageModel()\n",
    "    m = model.to(device)\n",
    "    print(sum(p.numel() for p in m.parameters())/1e6, 'M parameters')\n",
    "\n",
    "    # create a PyTorch optimizer\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    t0 = time.time()\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    for iter in range(max_iters):\n",
    "        # every once in a while evaluate the loss on train and val sets\n",
    "        if iter % eval_interval == 0 or iter == max_iters - 1:    \n",
    "            losses = estimate_loss()\n",
    "            train_loss = losses['train']\n",
    "            val_loss = losses['val']\n",
    "            print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "            train_losses.append(train_loss)\n",
    "            val_losses.append(val_loss)\n",
    "        # sample a batch of data\n",
    "        xb, yb = get_batch('train')\n",
    "\n",
    "        # evaluate the loss\n",
    "        logits, loss = model(xb, yb)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    t1 = time.time()\n",
    "    print(f\"Training took {t1 - t0:.2f} seconds\")\n",
    "\n",
    "    return train_losses, val_losses\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.1 Plot the training and validation losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(0, max_iters+1, eval_interval), train_losses, label='Train Loss')\n",
    "plt.plot(range(0, max_iters+1, eval_interval), val_losses, label='Val Loss')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. test the GPT model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b受找到客服的指导，服务很好，总之挺好的，下载速度也不错，信赖京东～～～～.\n",
      "我个人都觉得还不错，是正品，价廉物美，质量也略计真不错，给一个赞\n",
      "刚买回来就发现有点温，还没到一个月指望更新了\n",
      "刚收到货，衣服面料不错，是我喜欢的类型\n",
      "外观惊艳，高配上，媳妇一直想买一加手机。性能还是图慢一点就是4+64＋的64900多出现了点，非常流畅。颜值较高的游戏流畅，我发不玩游戏，已经在关闭最少600左右，电池耗电非常特别快，其他的配置没得说，感觉比9o，不发热运行不敢发热～～就走到手上，啥也没有的分量，这个本子装我可以这样的硬件还会好的！用了一段时间，发布好好感觉没有什么问题，就是拍照方面，款式也比较漂亮啊！推荐\n",
      "漏电严重，用了用了六年的手机待机半天，有时玩游戏有时接电话就一直有声屏，一天一，鬼，这也对京东失望了\n",
      "外观事很好，蓝色漂亮，配置高，吃鸡，流畅，烫手不卡，清晰度除了18小时处同生电池容量估计电保持续长2，一碰的话估计到一样！！！！必须吐槽(电池续航9~20hz看起来上去，跑分超低，再过一次去麻烦补200以内！?！！还不如买跑西三千下买的，玩游戏十局左右有用下角居然会花到了，居然要点什么运行内存一会4！！！！感觉！！！！！\n",
      "很好，很流畅\n",
      "速度快，低\n",
      "京东配送速度很快；昨天购买，现在可以提的可以送到货了、情咨询客服也确认到顾客地方谁来嘞!就给补点&ldquo;我听点：首先电脑背面质量还行\n",
      "速度很快，360C，自己用一年的X1居然坏了，因为这个所以就戴着我认为老婆买的，但是反正她用了一个月声明次出现一次重启，然后声音变很大，客服说无法跟卖家，不给说暂时没多大商量的问题，要收来证牌子的话边框就查了膜和保修条的单号，怎么是7行的，买的比人贵一点点不补偿，真是烦死人，有问题不是玩一下午都卡卡死几次，我就没有看那几个卡的比出来，我以前服务也是比较牛逼，这么**的网次不给差评\n",
      "先这个一年，什么都没有。\n",
      "快递包装！配送人的！华为手机也是一流的，跟苹果一样的赞！！！\n",
      "什么鬼手机，不怎么回事反应\n",
      "一分钱一分货也太低了，刚开机的时候屏幕边有明显的大声字幕不知道质量怎么样。手机的外观漂亮。还未拆机拆开递的倒是不敢恭维吧！后壳有时候看见有问题，插在一边出现反复说手机来用品外观工不能放！好了，最无奈的就是摄像头的问题方面的地方边的缝隙！怎么回事？发票都没有吗？怎么处理了！这么多拿的产品就这么说，已经50%电铃了？电脑质量不能用，求吧，就一局弹&rdqq了？冷，是系统的问题？\n",
      "这个质量我也是无语了今晚刚穿这鞋子和店里没有差别，衣服都好看，评价实际码有点变色偏略重，洗了没多少，根本穿的也都舒服，总之这次购物。\n",
      "有点不习惯，物有所值\n",
      "减震情况，给一颗星给小米再买的机子的要死，荣耀有些失望，8G内存内存，使用起来卡顿，内存也挺大，大家有32g的固盘剩下14g可用。如果卖听音乐就会冒一次品机，能不能一混一般，不能接受。另外，另最站开始视频还行时打开时一晃都不知道\n",
      "手机可以，只是华为的拖购提醒，我是拍下来的信息，那根本就是骗人的！\n",
      "宝贝收到了，质量很好，穿着很舒服，价格美丽，颜色也不错，喜欢，关键是客服专人员，还胶水褪色，不打算我买到期望值\n",
      "&hellip;&hellip;\n",
      "没有光驱。手机金属里面有东西过，摇角的胶粘轻感上全出汗，断断续续才能出现卡顿。还有，客服说不是东客服自己没辙地盆友言而售后。我绝对不会买苹果手机？？双摄像头一般都杠的500万的摄像头还有问题，摄像头用了一会刺眼模式，看着挺一般呢，其他暂时正常闪退现象。还不如我红米5plus，另外一个现在居然这两个airshos都会出来的？算了机子调出了什么都不行，把电脑做工负责人者想太折腾来的\n",
      "优点和之前的缺点太多吧，有一点。通话时杂音很多。玩刺激战场断断触。。。其余还好，用着感觉不舒服。感觉还没试以后的追评。。\n",
      "***，高配张千多手机就买了，还是一部分钱一分货。心态炸力一样。\n",
      "包装有点差评，为什么京东普遍的塑料塑料袋装进来的手机摔坏了，第一次把电源重给她。还有物流差评，同一时几帮同一天24号可以不足。在京东买笔记本，我看了无几个问题，遇到一次又安物流。再也不在京东速度快，鞋子确实漂亮，也买了两百多块钱。客服中心有于知道聊天记老板，还提送到\n",
      "很给力，打开后不知具了。手感很舒服，手感柔软舒适。\n",
      "容易坏，不停轴有一次逃掉，意思一下是电池容量太小了一抓\n",
      "拍照清晰，通话出乎意料，反应快，拍照清晰！\n",
      "感觉挺好的，颜色也喜欢。拍照也不错，发货速度快\n",
      "村来送来的，还有发货及时，物流感觉很不错，不满意，客服服务态度也很好，刚买完就降价了！\n",
      "买回来就是给我表弟用不的话充电就发烫，直接给我长的单子分钟去把原装充电就少一样，因为要给原我过没手机边以为手机卡爆-换一台，结果了九八百块的东西懒得是cpu不如劣质机器，下次在买苹果除啦～～～还要快递小哥态度也很好，我在商城买手机的朋友要注意我要你手机会不要过赚上千就算了，祝大家没有提醒大家买手段考虑下我也忍大家，给一星也是多多朋友看好几家店购买吧，否则不要让我表妹们对你的良心，我是给一星！对于这种的，回头果也是我欠钱一分货的钱一分货，我只想知道你们黑店，店\n",
      "总体来说还不错，拍照清晰\n",
      "刚收到第多满..宝宝要臭烧脚....\n",
      "快递超级到位，用着还不错，\n",
      "刚刚用三星Sim卡放，系统也垃圾，烂机，在线客服小气词，以前看是假货。给个差不多一个手机充电头拆开线就知道用不了，什么坑啊！想问这是不是小米吗？\n",
      "手机好好好，物流更给力，手机好，京东。\n",
      "说一下字有点大，照片就像，根本是帅体\n",
      "第一次用xx一样，后盖穿过后有很久才来评价，手机运行速度挺快的很稳定，玩游戏也不卡，游戏完全没出现什求生，分辨率40上一个月的645，v一个问题我要退货，客服告知激活了就是你扯了，可是不给退，哈哈我不知道买手机是干嘛激活不能不激活为在全做的，我买手机的话如果就是怎么拆封过的，因为客服会及时等到尾，不大，且确定，不投诉到京东也查不到延迟。不曾开封，可是在京东购物小米官网查过京东所以也改口不管该存认真相，可京东商城约定的问题，不谈京东的告诉京东赠品已经完全不给予回答，当时还是京东服务26天无理由；每次客服他们的客服微信给我电话协商，毫无用的申请退款时与我沟通根本不得适中等发货六次投诉后跟还我于从现在干七天的等怎么重复制登记；这种被不是坑人吗？看到的不是京东上与华为商家客服的态度？完全不了庇卖家客户电话处理，再认栽，我都不早认栽了，还是看京东对待消费者的。反正会隐瞒客户，很生气。\n",
      "没升级后版本稳定60   外观近啥都不行   这也多网友  就OK  满个微信  用鲁大电源3个小时     屏幕上也是没操作的   客服说 但是客服是同样的解释  等待时间120天后我去微星这几天遇到的电脑的包括有疑惑   这个评论上有这回答和京东客服  催客服 都是机器人   包括送绝对为啥手机  就一个包括我的了省包  数据线撒的小狗屎一样 连防烟都穿不了   真是太不爽了\n",
      "已收到，衣服样式精致，不错，大小合适。满意。\n",
      "很好，电脑一般，可以用十分的流畅，哈哈，有点不懂的选择。可惜问了客服态度非常好，答非常满意\n",
      "朋友请参下有什么不)，导航稳定一格信号难到，屏幕又调了一万，酷睿iknos驱动但是感觉很好看了种，激活前更天下载没了，外形精致，键盘是25乘的，键盘背光驱，屏幕特别滑，而且没有明显的纹丝不紧，售后太差了，一星期也懒得给个差评，大家看看！\n",
      "不好用，打电话都接不了，差评\n",
      "京东怎么说呢？到养的？\n",
      "不知为什么服务态度。明明就是默认重新购买机的信息的。还容易发热。\n",
      "挺不错的华为\n",
      "360手机。早上刚打游戏就发热，我的房子都不重进，还是要怎么用呢？@还不键除了，下载东西太差\n",
      "差评，手机用着还可以，晚上才知道，电池续航太差，京东自营差评差评\n",
      "宝贝不别错，包装也很到位，是win10系统，下载起来还是惠普想应用激活，这些功能也就这样吧，不知道什么原因。开机太慢，其服装好系统时电脑已经激活，这么low！开机特别慢！怕怪我看错了！所以骂人差评也是退不了！\n",
      "颜色挺好看的，十分不卡！\n",
      "价格实惠！已穿过几天，应该挺好的！商家态度很好！\n",
      "手机卡的狠卡   我个人都要退货   比如打个游戏啊  我不知道是不是翻新机   劝什么震动都会卡\n",
      "视频超轻 网速超慢 屏幕经常失灵  频率也掉到一样  尤其系统倒到什么前七天多 无服务\n",
      "鞋穿着舒服，满意的一次卖家，好评\n",
      "电脑整体性能不错，玩游戏留着点无瑕疵\n",
      "手机还可以说是现在考虑过的华为5、qapp经常打开直关机，红色的手机应该是新代一个。其他待用。喇叭声音混杂、耳机篮接凹陷，买了没有快递是1次品?\n",
      "运行流畅，电池玩水冷，尿刺，真的一般。。。。。。中兴没有敏感粘稠帶和R4天分辨率不高够快。。其次客服小姐服务态度热情，到位，送人完没有暴力。。专业，电脑OL、尺寸也够100多以外习惯性化。日常使用没发现任何玩游戏，正常lol都安装不上，问客服，也解决不了，需要是low，可以入手这款。\n",
      "还好，京东太垃圾，这里叫些电脑合适\n",
      "没发票？ 差评\n",
      "非常不错。但是为什么我买的6，一边故到后一只\n",
      "很烂的东西，失望死，手机不好用，充电没有杂音，不像实力派件，售后麻烦\n",
      "这款电话一点都不满意，打开不动，电量太差了吧。经常没反应。以后京东要买手机，大家谨慎购买\n",
      "先说好的赠品没，一个手机没有还有耳机。而且赠错么也不提前购买，欺骗顾客。\n",
      "第一次买酷派了，这个感觉低性，让我怎么想像中的好，圆通的7X也是第二次邮回买，还好客服态度也很差\n",
      "手机很流畅，配置不吹，处理器稳玩王者时珍惜了。主要是值得给五星！\n",
      "质量好，纯棉的。冬季房穿上跑步走路质感觉不错，清洗了不会特别有型，回头洗鞋上四次只能卖家，非常百搭\n",
      "太卡了，像素很棒！要买的好好再买吧！机器没打开，玩着网游都不会卡，给差评\n",
      "外观和做工不错，京东快递速度符合送货快，前包装也未廉价物流师傅带三星专门。\n",
      "怎么没有耳机？这评论也太离谱了吧，京东配太差了\n",
      "和图片的完全不一样好，除了有点大屏其他不像原因，不清晰\n",
      "用了三天就好，感觉还算可以，希望想穿用几天才知道\n",
      "很合适，版型也很好。\n",
      "一个破产机，，垃圾。塑料商面上使用，，，\n",
      "夏天穿，不怎么厚，，，\n",
      "很好，很喜欢\n",
      "全高大上的评价电脑，秒明天一药场正的新物车载 ，电脑自己看电脑自带的分区，电脑到机箱子啥状都没装，还带了一天，还会正常的软件，看了电源硬盘就久了，心情肯白浅，激活完没什么大问题。\n",
      "买手机一个原装膜加钢化膜 充电器不能放纯充电\n",
      "被人用过的感觉，第一次网购慢递员态度恶劣，赠品竟然完了但给个电话，手机充电器使用充电器充好几分劲的，第一次不敢买了，说好的换货怎么还不知道意思，脏的，新装，反正认倒霉了，必须等一个多月才给差评\n",
      "号码合适，穿比较舒服\n",
      "屏幕还是漏电，联系客服，没有答复反应，叫我最#的是，\n",
      "货卖家及时还信赖，Mac\n",
      "值得推荐，二天没穿，越来越合脚了！\n",
      "客服态度差，一是开商品不给退，有问题劲\n",
      "发烫，\n",
      "质量还不错，穿着也舒服，一百多少这个条灵，下次还来我还敢再买一双靴子！\n",
      "不好，盗版的\n",
      "快递太慢\n",
      "指纹解锁，之前摄像头都不如新，华为手机软件难用，老爷子用着还可以，就是四五次才能，能多解锁格式也一般般啦?你就发热。一颗星都不给\n",
      "昨天买第午就降价100，说啥贵减差评?呢。\n",
      "价美物廉值得拥有\\\\n第一天穿一天，感觉还不错，下载了微信，看电影够用，不知道为何用好不用习惯就好，实话实说，别的暂时没什么斜纹，足再看了咯。鲁大师一下分。\n",
      "电脑性能超极其不错，非常满意，总得来说还有现在在的电脑包，这次也是。\n",
      "颜值很好，穿着很舒服，非常的不错，值得拥有推荐！\n",
      "用了几天微博就出现卡机，散热也差\n",
      "很差的购物体验。没货，也就不得不说了。垃圾。。快递，服务态度还好，大家要慎重。时间长就长。。\n",
      "手机一般，声音太小，没有杂音，要买的话还容易看看是别人退货机卡还老人，后悔没有好的手机\n",
      "垃圾手机，没有耳机\n",
      "便宜100刚买的红米5i 震撼到我说话后期用的感觉有些失灵就发烫， 以为吃鸡\n",
      "跑分只是37没得到，怪自由于没有带电脑外观 内部散热  乱按还是没有什么用 win10无所谓还要正版  以为自己配了屏幕 超级容易\n"
     ]
    }
   ],
   "source": [
    "# generate from the model\n",
    "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
    "print(decode(m.generate(context, max_new_tokens=5000)[0].tolist()))\n",
    "# open('more.txt', 'w').write(decode(m.generate(context, max_new_tokens=10000)[0].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'minbpe'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mminbpe\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RegexTokenizer\n\u001b[0;32m      3\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m RegexTokenizer()\n\u001b[0;32m      4\u001b[0m tokenizer\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtok32k.model\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;66;03m# loads the model back from disk\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'minbpe'"
     ]
    }
   ],
   "source": [
    "from minbpe\n",
    "import RegexTokenizer\n",
    "\n",
    "tokenizer = RegexTokenizer()\n",
    "tokenizer.load(\"tok32k.model\") # loads the model back from disk\n",
    "\n",
    "tokenizer.encode(\"hello world\") # string -> tokens\n",
    "tokenizer.decode([1000, 2000, 3000]) # tokens -> string\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bayesianproject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
